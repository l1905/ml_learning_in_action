{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前期数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性函数：\n",
    "$\\hat y = \\sigma(W^Tx + b) $\n",
    "\n",
    "sigmoid函数相关: \n",
    "$\\sigma(z) = \\frac{1}{1+e^{-z}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们约定:\n",
    "$ \\hat y = P(y=1\\mid x)$\n",
    "\n",
    "如果 y=1 : $ P(y\\mid x) = \\hat y$\n",
    "\n",
    "如果 y=0 : $ P(y\\mid x) = 1 - \\hat y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并整合上述公式\n",
    "$ P(y\\mid x) = \\hat y^{y} (1-\\hat y)^{1-y} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log 函数严格单调递增， 左右两边取log，  备注 $\\ell 为损失函数$\n",
    "\n",
    "$ logP(y\\mid x) = log\\hat y^{y} (1-\\hat y)^{1-y} = ylog\\hat y + (1-y)log(1- \\hat y) = -\\ell (\\hat y, y)$ \n",
    "\n",
    "原因是： 希望概率越大， 则损失函数越小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对整个训练集: P(lables in training set) = $ \\prod_{i=1}^{m}P(y^{i}\\mid x^{i}) $\n",
    "\n",
    "我们需要将其概率最大化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 概念：最大似然值(maximum likehood estimation) , 即求出一组参数，使得整个公式取得最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "左右取log\n",
    "\n",
    " log(P(lables in training set)) =  $ log(\\prod_{i=1}^{m}P(y^{i}\\mid x^{i})) = \\sum_{i=1}^{m}log(P(y^i \\mid x^i) = -\\sum_{i=1}^{m}\\ell (\\hat y^{i}, y^{i}) $\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "成本函数:cost mimminze:\n",
    "\n",
    "$ \\jmath (w, b) = \\frac{1}{m}\\sum_{i=1}^{m} \\ell (\\hat y^{i}, y^{i}) $\n",
    "\n",
    "$\\frac {1}{m}$ 主要是为了对成本函数进行适当的缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\ell (\\hat y, y) = -ylog\\hat{y} - (1-y)log(1-\\hat{y}) $\n",
    "\n",
    "我们的最终目的是使损失函数的值最小化\n",
    "\n",
    "如果y = 1, $ \\ell(\\hat y, y) = -log\\hat{y} $ 因此可知，为了损失最小， $\\hat y$需要尽可能的大\n",
    "\n",
    "如果y = 0, $ \\ell(\\hat y, y) = -log(1-\\hat{y}) $ 因此可知， 为了损失最小， $\\hat y$需要尽可能的大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 成本函数相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\jmath (w, b) = \\frac{1}{m}\\sum_{i=1}^{m} \\ell (\\hat y^{i}, y^{i}) = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{i}log(\\hat y^{i}) + (1-y^{i})log(1-\\hat y^{i})) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算偏导 梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经知道有以下公式成立\n",
    "\n",
    "$$ z = w^{T} + b$$\n",
    "$$ \\hat y = a = \\sigma(z) $$\n",
    "$$ \\ell (a, y) = -yloga - (1-y)log(1-a) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "并且我们已知有以下推导链"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ z = w_{1}x + w_{2}x + ...+b \\Longrightarrow \\hat{y} = a = \\sigma(z) \\Longrightarrow \\ell (a, y)  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先对a求导\n",
    "\n",
    "$ da = \\frac{d{\\ell}}{da} = d(a,y) = d(-yloga - (1-y)log(1-a)) = -\\frac{y}{a} + \\frac{1-y}{1-a} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们对Z求导\n",
    "\n",
    "$ dz = \\frac{d{\\ell}}{dz} = \\frac{d{\\ell}}{da} \\cdot \\frac{da}{dz} = da \\cdot \\frac{da}{dz} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "da我们刚才已经求出， 因此现在我们只需要求导 $\\frac{da}{dz}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{align}\n",
    "\\frac{da}{dz} &= (\\frac{1}{1+e^{-z}})^{'} \\tag{1}\\\\\n",
    "&= \\frac{-(1+e^{-z})^{'}}{(1+e^{-z})^{2}} \\tag{2}\\\\\n",
    "&= \\frac{e^{-z}}{(1+e^{-z})^{2}} \\tag{3}\\\\\n",
    "&= \\frac{e^{-z}+1-1}{(1+e^{-z})^{2}} \\tag{4}\\\\\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot (1 - \\frac{1}{(1+e^{-z})}) \\tag{5}\\\\\n",
    "&= a \\cdot (1-a) \\tag{6}\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此我们可以求出\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "dz &= da \\cdot \\frac{da}{dz} \\tag{1}\\\\\n",
    "dz &= (-\\frac{y}{a} + \\frac{1-y}{1-a}) \\cdot a \\cdot (1-a) \\tag{2}\\\\\n",
    "dz &= a - y \\tag{3}\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终我们求出 dw偏导\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "dw &= \\frac{dz}{dw} \\cdot dz \\tag{1}\\\\\n",
    "dw &= x \\cdot (a-y)\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数学求导相关公式 http://math2.org/math/derivatives/identities.htm#quotient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
